{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction and Project Overview\n",
    "\n",
    "This project is designed to be an engaging, hands-on experience in the world of machine learning and object detection. Our goal is to explore and compare the performance of different models in a dynamic, real-time environment.\n",
    "\n",
    "### Objective\n",
    "We aim to deploy three different models to identify and classify animals in a live video. Our dataset focuses on five animal classes: Crocodile, Fox, Giraffe, Panda, and Raccoon. Each class has 100 images, culminating in a diverse set of 500 images.\n",
    "\n",
    "### Models and Approach\n",
    "We'll be using models from the Detectron2 framework, a state-of-the-art object detection library developed by Facebook AI Research. Our approach is as follows:\n",
    "1. **Model Selection**: We'll select two pre-trained Detectron2 models to use as-is.\n",
    "2. **Model Finetuning**: We'll finetune a third Detectron2 model on our custom animal dataset for a tailored approach.\n",
    "3. **Real-Time Evaluation**: These models will be tested in real-time by processing a video that contains instances of our target animals. We'll assess and compare their performance based on accuracy and speed.\n",
    "\n",
    "### Let's get started!\n",
    "Follow along as we set up our environment, prepare our dataset, finetune our model, and evaluate the results."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50d83b8428695c49"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking and Installing Required Libraries\n",
    "\n",
    "In this section, we'll ensure that all the required libraries for our project are installed and ready to use. This includes PyTorch, torchvision, OpenCV, and Detectron2.\n",
    "\n",
    "### 1. Verifying PyTorch and torchvision Installation\n",
    "\n",
    "PyTorch is the backbone of our models, so it's essential to have it installed. Let's check if PyTorch and torchvision are already installed. If not, we'll install them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3722df783aa83f3"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.1+cu121\n",
      "torchvision version: 0.16.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Function to install packages\n",
    "def install_package(package_name):\n",
    "    !{sys.executable} -m pip install {package_name}\n",
    "\n",
    "# Check for PyTorch\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch is not installed. Installing now...\")\n",
    "    install_package(\"torch torchvision\")\n",
    "\n",
    "# Check torchvision\n",
    "try:\n",
    "    import torchvision\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"torchvision is not installed. Installing now...\")\n",
    "    install_package(\"torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T15:23:51.338847Z",
     "start_time": "2023-11-21T15:23:49.456261400Z"
    }
   },
   "id": "ce6b40e6869b8d69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Installing OpenCV and Checking CUDA Availability\n",
    "\n",
    "Here we check for CUDA availability. If CUDA is available, PyTorch will use GPU acceleration, which will significantly speed up our training and inference. If CUDA is not available, PyTorch will use CPU. We'll also install OpenCV, which we'll use for video processing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9febcfe076b3567c"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. PyTorch is using GPU acceleration!\n",
      "OpenCV version: 4.8.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check for CUDA\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. PyTorch is using GPU acceleration!\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch is using CPU.\")\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "    print(f\"OpenCV version: {cv2.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"OpenCV is not installed. Installing now...\")\n",
    "    install_package(\"opencv-python-headless\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T15:23:52.601628100Z",
     "start_time": "2023-11-21T15:23:51.334847800Z"
    }
   },
   "id": "6b438749caaae9db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Installing Detectron2 from Source\n",
    "\n",
    "Installing Detectron2 from source allows us to work with the latest version of the library. This method requires gcc & g++ (version 5.4 or higher). If you have these prerequisites, you can proceed with the installation; otherwise, please install them first."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddea5023ca4db57f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ninja in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (1.11.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to c:\\users\\diego\\appdata\\local\\temp\\pip-req-build-qen2s3uf\n",
      "  Resolved https://github.com/facebookresearch/detectron2.git to commit 017abbfa5f2c2a2afa045200c2af9ccf2fc6227f\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: Pillow>=7.1 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (10.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (3.8.2)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (2.0.7)\n",
      "Requirement already satisfied: termcolor>=1.1 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (2.3.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (0.1.8)\n",
      "Requirement already satisfied: tabulate in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (0.9.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (3.0.0)\n",
      "Requirement already satisfied: tqdm>4.29.0 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (4.66.1)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (2.15.1)\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (0.1.9)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.1 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (2.3.0)\n",
      "Requirement already satisfied: hydra-core>=1.1 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (1.3.2)\n",
      "Requirement already satisfied: black in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (23.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from detectron2==0.6) (23.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
      "Requirement already satisfied: portalocker in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from matplotlib->detectron2==0.6) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from matplotlib->detectron2==0.6) (4.44.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from matplotlib->detectron2==0.6) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from matplotlib->detectron2==0.6) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from tqdm>4.29.0->detectron2==0.6) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from black->detectron2==0.6) (8.1.7)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from black->detectron2==0.6) (1.0.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from black->detectron2==0.6) (0.11.2)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from black->detectron2==0.6) (3.11.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from black->detectron2==0.6) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from black->detectron2==0.6) (4.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from tensorboard->detectron2==0.6) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from tensorboard->detectron2==0.6) (1.59.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from tensorboard->detectron2==0.6) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from tensorboard->detectron2==0.6) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from tensorboard->detectron2==0.6) (3.5.1)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from tensorboard->detectron2==0.6) (4.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from tensorboard->detectron2==0.6) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from tensorboard->detectron2==0.6) (68.2.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from tensorboard->detectron2==0.6) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.3)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from portalocker->iopath<0.1.10,>=0.1.7->detectron2==0.6) (306)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\diego\\pycharmprojects\\classificationcontest\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git 'C:\\Users\\diego\\AppData\\Local\\Temp\\pip-req-build-qen2s3uf'\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install ninja for faster build\n",
    "!pip install ninja\n",
    "\n",
    "# Clone the Detectron2 repository\n",
    "!python -m pip install git+https://github.com/facebookresearch/detectron2.git"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T15:24:01.458353300Z",
     "start_time": "2023-11-21T15:23:52.598627300Z"
    }
   },
   "id": "c2a93e7c982657a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note**: Building from source might take some time. If you encounter any issues, please refer to the [Detectron2 installation documentation](https://detectron2.readthedocs.io/en/latest/tutorials/install.html) for troubleshooting tips and alternative installation methods."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "963e058853df79b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Download and Preparation\n",
    "\n",
    "This section focuses on downloading your custom animal dataset and preparing it for use with Detectron2.\n",
    "\n",
    "### Downloading the Dataset\n",
    "\n",
    "First, we need to download and extract the dataset from the provided link."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90443e8a49ad0189"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "\n",
    "# URL to the dataset\n",
    "dataset_url = \"https://github.com/D-Gaspa/Animal-BoVW-Classifier/releases/download/1.0/animals_dataset.zip\"\n",
    "\n",
    "# Download the dataset\n",
    "response = requests.get(dataset_url)\n",
    "zip_file = ZipFile(BytesIO(response.content))\n",
    "# Create a folder to extract the dataset\n",
    "!mkdir Dataset\n",
    "# Extract the dataset to the created folder\n",
    "zip_file.extractall(\"Dataset\")\n",
    "print(\"Dataset downloaded and extracted successfully!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T15:24:05.756331900Z",
     "start_time": "2023-11-21T15:24:01.459352700Z"
    }
   },
   "id": "890212641a595916"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparing the Dataset for Detectron2\n",
    "\n",
    "Detectron2 requires the dataset to be in a specific format. We'll create a function to convert our dataset into this format."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f7c45a2bf4d7b22"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset registered successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import detectron2.structures\n",
    "\n",
    "def get_my_dataset_dicts(dataset_dir, annotation_file):\n",
    "    with open(annotation_file) as f:\n",
    "        annotations = json.load(f)\n",
    "\n",
    "    dataset_dicts = []\n",
    "    for filename, objs in annotations.items():\n",
    "        record = {}\n",
    "        file_path = os.path.join(dataset_dir, filename)\n",
    "        record[\"file_name\"] = file_path\n",
    "\n",
    "        image = Image.open(file_path)\n",
    "        record[\"width\"], record[\"height\"] = image.size  # Ensure correct ordering\n",
    "\n",
    "        record[\"annotations\"] = []\n",
    "        for obj in objs:\n",
    "            obj[\"bbox_mode\"] = detectron2.structures.BoxMode.XYWH_ABS\n",
    "            record[\"annotations\"].append(obj)\n",
    "\n",
    "        dataset_dicts.append(record)\n",
    "\n",
    "    return dataset_dicts\n",
    "\n",
    "# Register the dataset\n",
    "from detectron2.data import DatasetCatalog\n",
    "DatasetCatalog.register(\"my_dataset\", lambda: get_my_dataset_dicts(\"Dataset\", \"Dataset/annotations.json\"))\n",
    "\n",
    "print(\"Dataset registered successfully!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T15:24:05.981151800Z",
     "start_time": "2023-11-21T15:24:05.759820400Z"
    }
   },
   "id": "bb0369b64078913c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function will format your dataset for Detectron2, considering the specific structure and annotation format of your dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cad06277b1a47958"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Selection and Loading\n",
    "\n",
    "In this part of our project, we will select and load pre-trained models from Detectron2's model zoo. Detectron2 offers a wide range of models that are pre-trained on various datasets. We will choose two distinct models for our initial comparison and later introduce a finetuned version of one of these models.\n",
    "\n",
    "### Loading Pre-Trained Models\n",
    "\n",
    "Detectron2 makes it easy to load pre-trained models. Here’s how you can do it:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22e1edf5b12f0127"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 loaded successfully!\n",
      "Model 2 loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "def load_model(model_name):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(model_name))\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set threshold for this model\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model_name)\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    return predictor, cfg\n",
    "\n",
    "# Example of loading two models\n",
    "model_1, cfg_for_model_1 = load_model(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "print(\"Model 1 loaded successfully!\")\n",
    "model_2, cfg_for_model_2 = load_model(\"COCO-Detection/faster_rcnn_R_50_DC5_3x.yaml\")\n",
    "print(\"Model 2 loaded successfully!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T15:24:08.016309500Z",
     "start_time": "2023-11-21T15:24:05.978151300Z"
    }
   },
   "id": "e6ff19d353de5fb3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Choosing Different Models for Comparison\n",
    "\n",
    "Detectron2’s model zoo contains a variety of models pre-trained on different datasets like COCO, Cityscapes, etc. When choosing models for comparison, consider the following:\n",
    "\n",
    "- **Model Architecture**: Different architectures like Faster R-CNN, Mask R-CNN have their own strengths and weaknesses.\n",
    "- **Backbone**: The backbone (like ResNet-50, ResNet-101) impacts the model's accuracy and speed.\n",
    "    - FPN: Uses a ResNet+FPN backbone with standard conv and FC heads for mask and box prediction, respectively. It obtains the best speed/accuracy tradeoff.\n",
    "    - DC5 (Dilated-C5): Uses a ResNet conv5 backbone with dilations in conv5, and standard conv and FC heads for mask and box prediction, respectively.\n",
    "\n",
    "You can explore the [Detectron2 model zoo](https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md) to see all available options."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cbf157e7561099"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selection Analysis of Faster R-CNN R 50 DC5 3x and Faster R-CNN R 50 FPN 3x for Animal Detection\n",
    "\n",
    "**Faster R-CNN R 50 DC5 3x: Specialized Detail Recognition**\n",
    "The Faster R-CNN R 50 DC5 3x model is chosen for its enhanced capability in capturing fine details, an essential feature for detecting smaller or camouflaged animals. This model employs dilated convolutions, which increase the receptive field of the network without losing resolution. This aspect is particularly beneficial in identifying subtle features of animals, such as patterns or markings, that are crucial for accurate detection in complex natural environments.\n",
    "\n",
    "**Faster R-CNN R 50 FPN 3x: Mastering Scale Variability**\n",
    "On the other hand, the Faster R-CNN R 50 FPN 3x is selected for its proficiency in handling scale variability, a common challenge in animal detection. The Feature Pyramid Network (FPN) within this model is adept at detecting objects at multiple scales, making it ideal for identifying animals that vary significantly in size. This feature is invaluable in scenarios where animals may appear at different distances from the camera, ensuring consistent detection accuracy regardless of scale."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b33e732ffb0dcc52"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finetuning the Model\n",
    "\n",
    "Finetuning a pre-trained model involves adjusting it slightly to perform better on our specific dataset. We will select one of the pre-trained models and retrain it on our animal dataset.\n",
    "\n",
    "### Steps for Finetuning\n",
    "\n",
    "1. **Load a Pre-Trained Model**: First, load a model from Detectron2's model zoo as a starting point.\n",
    "\n",
    "2. **Modify for Our Dataset**: Since our dataset has 5 classes, we need to adjust the model's final layer to reflect this.\n",
    "\n",
    "3. **Retrain the Model**: Finally, we'll retrain the model on our dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18c80d030720921f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[11/21 09:24:08 d2.engine.defaults]: \u001B[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001B[32m[11/21 09:24:11 d2.data.build]: \u001B[0mRemoved 0 images with no usable annotations. 500 images left.\n",
      "\u001B[32m[11/21 09:24:11 d2.data.dataset_mapper]: \u001B[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001B[32m[11/21 09:24:11 d2.data.build]: \u001B[0mUsing training sampler TrainingSampler\n",
      "\u001B[32m[11/21 09:24:11 d2.data.common]: \u001B[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001B[32m[11/21 09:24:11 d2.data.common]: \u001B[0mSerializing 500 elements to byte tensors and concatenating them all ...\n",
      "\u001B[32m[11/21 09:24:11 d2.data.common]: \u001B[0mSerialized dataset takes 0.09 MiB\n",
      "\u001B[32m[11/21 09:24:11 d2.data.build]: \u001B[0mMaking batched data loader with batch_size=2\n",
      "\u001B[32m[11/21 09:24:11 d2.checkpoint.detection_checkpoint]: \u001B[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001B[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001B[0m\n",
      "\u001B[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[11/21 09:24:11 d2.engine.train_loop]: \u001B[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\PycharmProjects\\ClassificationContest\\venv\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[11/21 09:24:20 d2.utils.events]: \u001B[0m eta: 0:10:56  iter: 19  total_loss: 2.399  loss_cls: 1.866  loss_box_reg: 0.06872  loss_rpn_cls: 0.3996  loss_rpn_loc: 0.05252    time: 0.2665  last_time: 0.3078  data_time: 0.1122  last_data_time: 0.0010   lr: 4.9953e-06  max_mem: 3344M\n",
      "\u001B[32m[11/21 09:24:25 d2.utils.events]: \u001B[0m eta: 0:10:26  iter: 39  total_loss: 2.982  loss_cls: 1.683  loss_box_reg: 0.02095  loss_rpn_cls: 0.993  loss_rpn_loc: 0.1399    time: 0.2572  last_time: 0.2416  data_time: 0.0011  last_data_time: 0.0007   lr: 9.9902e-06  max_mem: 3435M\n",
      "\u001B[32m[11/21 09:24:30 d2.utils.events]: \u001B[0m eta: 0:10:05  iter: 59  total_loss: 1.76  loss_cls: 1.254  loss_box_reg: 0.07628  loss_rpn_cls: 0.2984  loss_rpn_loc: 0.06066    time: 0.2516  last_time: 0.2363  data_time: 0.0011  last_data_time: 0.0008   lr: 1.4985e-05  max_mem: 3435M\n",
      "\u001B[32m[11/21 09:24:35 d2.utils.events]: \u001B[0m eta: 0:09:48  iter: 79  total_loss: 1.57  loss_cls: 0.8973  loss_box_reg: 0.06359  loss_rpn_cls: 0.4651  loss_rpn_loc: 0.1022    time: 0.2479  last_time: 0.2139  data_time: 0.0010  last_data_time: 0.0012   lr: 1.998e-05  max_mem: 3435M\n",
      "\u001B[32m[11/21 09:24:40 d2.utils.events]: \u001B[0m eta: 0:09:45  iter: 99  total_loss: 1.827  loss_cls: 0.5  loss_box_reg: 0.02542  loss_rpn_cls: 0.8127  loss_rpn_loc: 0.3614    time: 0.2486  last_time: 0.2249  data_time: 0.0011  last_data_time: 0.0014   lr: 2.4975e-05  max_mem: 3435M\n",
      "\u001B[32m[11/21 09:24:44 d2.utils.events]: \u001B[0m eta: 0:09:39  iter: 119  total_loss: 1.381  loss_cls: 0.3  loss_box_reg: 0.0539  loss_rpn_cls: 0.5333  loss_rpn_loc: 0.3792    time: 0.2468  last_time: 0.2688  data_time: 0.0010  last_data_time: 0.0010   lr: 2.997e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:24:49 d2.utils.events]: \u001B[0m eta: 0:09:33  iter: 139  total_loss: 0.7152  loss_cls: 0.2301  loss_box_reg: 0.03232  loss_rpn_cls: 0.2529  loss_rpn_loc: 0.1909    time: 0.2454  last_time: 0.2345  data_time: 0.0010  last_data_time: 0.0011   lr: 3.4965e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:24:54 d2.utils.events]: \u001B[0m eta: 0:09:27  iter: 159  total_loss: 0.5568  loss_cls: 0.1754  loss_box_reg: 0.07055  loss_rpn_cls: 0.111  loss_rpn_loc: 0.1433    time: 0.2450  last_time: 0.2560  data_time: 0.0010  last_data_time: 0.0007   lr: 3.996e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:24:59 d2.utils.events]: \u001B[0m eta: 0:09:19  iter: 179  total_loss: 0.5371  loss_cls: 0.1326  loss_box_reg: 0.08065  loss_rpn_cls: 0.07295  loss_rpn_loc: 0.1996    time: 0.2435  last_time: 0.2549  data_time: 0.0010  last_data_time: 0.0009   lr: 4.4955e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:25:03 d2.utils.events]: \u001B[0m eta: 0:09:14  iter: 199  total_loss: 0.8069  loss_cls: 0.0868  loss_box_reg: 0.03216  loss_rpn_cls: 0.1198  loss_rpn_loc: 0.416    time: 0.2427  last_time: 0.2553  data_time: 0.0010  last_data_time: 0.0007   lr: 4.995e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:25:08 d2.utils.events]: \u001B[0m eta: 0:09:08  iter: 219  total_loss: 0.4541  loss_cls: 0.1106  loss_box_reg: 0.04615  loss_rpn_cls: 0.07459  loss_rpn_loc: 0.1265    time: 0.2420  last_time: 0.2639  data_time: 0.0010  last_data_time: 0.0007   lr: 5.4945e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:25:13 d2.utils.events]: \u001B[0m eta: 0:09:03  iter: 239  total_loss: 0.6069  loss_cls: 0.0944  loss_box_reg: 0.05499  loss_rpn_cls: 0.08159  loss_rpn_loc: 0.2593    time: 0.2418  last_time: 0.2335  data_time: 0.0010  last_data_time: 0.0007   lr: 5.994e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:25:18 d2.utils.events]: \u001B[0m eta: 0:08:59  iter: 259  total_loss: 0.4772  loss_cls: 0.1062  loss_box_reg: 0.08366  loss_rpn_cls: 0.09411  loss_rpn_loc: 0.2301    time: 0.2423  last_time: 0.2517  data_time: 0.0011  last_data_time: 0.0011   lr: 6.4935e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:25:23 d2.utils.events]: \u001B[0m eta: 0:08:56  iter: 279  total_loss: 0.387  loss_cls: 0.1074  loss_box_reg: 0.0682  loss_rpn_cls: 0.0699  loss_rpn_loc: 0.1204    time: 0.2426  last_time: 0.2015  data_time: 0.0010  last_data_time: 0.0011   lr: 6.993e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:25:28 d2.utils.events]: \u001B[0m eta: 0:08:51  iter: 299  total_loss: 0.5117  loss_cls: 0.09958  loss_box_reg: 0.08045  loss_rpn_cls: 0.06347  loss_rpn_loc: 0.2665    time: 0.2432  last_time: 0.2370  data_time: 0.0010  last_data_time: 0.0010   lr: 7.4925e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:25:32 d2.utils.events]: \u001B[0m eta: 0:08:46  iter: 319  total_loss: 0.7163  loss_cls: 0.07909  loss_box_reg: 0.04707  loss_rpn_cls: 0.09269  loss_rpn_loc: 0.2775    time: 0.2428  last_time: 0.2371  data_time: 0.0009  last_data_time: 0.0007   lr: 7.992e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:25:37 d2.utils.events]: \u001B[0m eta: 0:08:41  iter: 339  total_loss: 0.4152  loss_cls: 0.1057  loss_box_reg: 0.07731  loss_rpn_cls: 0.079  loss_rpn_loc: 0.1356    time: 0.2428  last_time: 0.2877  data_time: 0.0010  last_data_time: 0.0008   lr: 8.4915e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:25:42 d2.utils.events]: \u001B[0m eta: 0:08:37  iter: 359  total_loss: 0.3772  loss_cls: 0.0936  loss_box_reg: 0.06358  loss_rpn_cls: 0.08291  loss_rpn_loc: 0.1575    time: 0.2432  last_time: 0.2684  data_time: 0.0010  last_data_time: 0.0009   lr: 8.991e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:25:47 d2.utils.events]: \u001B[0m eta: 0:08:32  iter: 379  total_loss: 0.4261  loss_cls: 0.09972  loss_box_reg: 0.06908  loss_rpn_cls: 0.06599  loss_rpn_loc: 0.1017    time: 0.2428  last_time: 0.1891  data_time: 0.0011  last_data_time: 0.0012   lr: 9.4905e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:25:52 d2.utils.events]: \u001B[0m eta: 0:08:27  iter: 399  total_loss: 0.4317  loss_cls: 0.1038  loss_box_reg: 0.06448  loss_rpn_cls: 0.06571  loss_rpn_loc: 0.1825    time: 0.2426  last_time: 0.2495  data_time: 0.0010  last_data_time: 0.0014   lr: 9.99e-05  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:25:57 d2.utils.events]: \u001B[0m eta: 0:08:22  iter: 419  total_loss: 0.4749  loss_cls: 0.1151  loss_box_reg: 0.06775  loss_rpn_cls: 0.08873  loss_rpn_loc: 0.1559    time: 0.2425  last_time: 0.2782  data_time: 0.0010  last_data_time: 0.0011   lr: 0.0001049  max_mem: 3436M\n",
      "\u001B[32m[11/21 09:26:02 d2.utils.events]: \u001B[0m eta: 0:08:17  iter: 439  total_loss: 0.449  loss_cls: 0.09449  loss_box_reg: 0.07084  loss_rpn_cls: 0.08931  loss_rpn_loc: 0.1433    time: 0.2429  last_time: 0.2018  data_time: 0.0012  last_data_time: 0.0011   lr: 0.00010989  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:26:07 d2.utils.events]: \u001B[0m eta: 0:08:13  iter: 459  total_loss: 0.3802  loss_cls: 0.1207  loss_box_reg: 0.1011  loss_rpn_cls: 0.07483  loss_rpn_loc: 0.1337    time: 0.2430  last_time: 0.2269  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00011489  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:26:11 d2.utils.events]: \u001B[0m eta: 0:08:08  iter: 479  total_loss: 0.6551  loss_cls: 0.08378  loss_box_reg: 0.02466  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.3657    time: 0.2427  last_time: 0.2429  data_time: 0.0011  last_data_time: 0.0011   lr: 0.00011988  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:26:16 d2.utils.events]: \u001B[0m eta: 0:08:04  iter: 499  total_loss: 0.3374  loss_cls: 0.07635  loss_box_reg: 0.04324  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.05813    time: 0.2429  last_time: 0.2379  data_time: 0.0011  last_data_time: 0.0013   lr: 0.00012488  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:26:21 d2.utils.events]: \u001B[0m eta: 0:07:59  iter: 519  total_loss: 0.3761  loss_cls: 0.08961  loss_box_reg: 0.04846  loss_rpn_cls: 0.07087  loss_rpn_loc: 0.1216    time: 0.2429  last_time: 0.2489  data_time: 0.0011  last_data_time: 0.0009   lr: 0.00012987  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:26:26 d2.utils.events]: \u001B[0m eta: 0:07:54  iter: 539  total_loss: 0.3282  loss_cls: 0.08874  loss_box_reg: 0.06465  loss_rpn_cls: 0.04557  loss_rpn_loc: 0.0931    time: 0.2433  last_time: 0.2423  data_time: 0.0010  last_data_time: 0.0010   lr: 0.00013487  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:26:31 d2.utils.events]: \u001B[0m eta: 0:07:50  iter: 559  total_loss: 0.4046  loss_cls: 0.096  loss_box_reg: 0.04183  loss_rpn_cls: 0.07086  loss_rpn_loc: 0.1808    time: 0.2430  last_time: 0.1835  data_time: 0.0011  last_data_time: 0.0008   lr: 0.00013986  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:26:36 d2.utils.events]: \u001B[0m eta: 0:07:45  iter: 579  total_loss: 0.5813  loss_cls: 0.1248  loss_box_reg: 0.09381  loss_rpn_cls: 0.07423  loss_rpn_loc: 0.2738    time: 0.2430  last_time: 0.2573  data_time: 0.0009  last_data_time: 0.0008   lr: 0.00014486  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:26:41 d2.utils.events]: \u001B[0m eta: 0:07:40  iter: 599  total_loss: 0.4365  loss_cls: 0.1084  loss_box_reg: 0.06916  loss_rpn_cls: 0.07144  loss_rpn_loc: 0.14    time: 0.2431  last_time: 0.2287  data_time: 0.0009  last_data_time: 0.0006   lr: 0.00014985  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:26:46 d2.utils.events]: \u001B[0m eta: 0:07:36  iter: 619  total_loss: 0.5704  loss_cls: 0.1398  loss_box_reg: 0.1298  loss_rpn_cls: 0.05265  loss_rpn_loc: 0.1697    time: 0.2433  last_time: 0.2453  data_time: 0.0010  last_data_time: 0.0007   lr: 0.00015485  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:26:50 d2.utils.events]: \u001B[0m eta: 0:07:30  iter: 639  total_loss: 0.3296  loss_cls: 0.1016  loss_box_reg: 0.06813  loss_rpn_cls: 0.06575  loss_rpn_loc: 0.04742    time: 0.2430  last_time: 0.2293  data_time: 0.0010  last_data_time: 0.0008   lr: 0.00015984  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:26:55 d2.utils.events]: \u001B[0m eta: 0:07:26  iter: 659  total_loss: 0.2896  loss_cls: 0.101  loss_box_reg: 0.08222  loss_rpn_cls: 0.08374  loss_rpn_loc: 0.03302    time: 0.2430  last_time: 0.2435  data_time: 0.0010  last_data_time: 0.0010   lr: 0.00016484  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:27:00 d2.utils.events]: \u001B[0m eta: 0:07:21  iter: 679  total_loss: 0.5123  loss_cls: 0.1144  loss_box_reg: 0.07117  loss_rpn_cls: 0.06621  loss_rpn_loc: 0.1667    time: 0.2430  last_time: 0.2043  data_time: 0.0010  last_data_time: 0.0007   lr: 0.00016983  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:27:05 d2.utils.events]: \u001B[0m eta: 0:07:17  iter: 699  total_loss: 0.3751  loss_cls: 0.1143  loss_box_reg: 0.0739  loss_rpn_cls: 0.0901  loss_rpn_loc: 0.08121    time: 0.2433  last_time: 0.2442  data_time: 0.0009  last_data_time: 0.0013   lr: 0.00017483  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:27:10 d2.utils.events]: \u001B[0m eta: 0:07:12  iter: 719  total_loss: 0.4181  loss_cls: 0.1273  loss_box_reg: 0.09935  loss_rpn_cls: 0.05724  loss_rpn_loc: 0.1591    time: 0.2435  last_time: 0.2901  data_time: 0.0011  last_data_time: 0.0006   lr: 0.00017982  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:27:15 d2.utils.events]: \u001B[0m eta: 0:07:08  iter: 739  total_loss: 0.6152  loss_cls: 0.1134  loss_box_reg: 0.07723  loss_rpn_cls: 0.08142  loss_rpn_loc: 0.2652    time: 0.2435  last_time: 0.2539  data_time: 0.0009  last_data_time: 0.0011   lr: 0.00018482  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:27:20 d2.utils.events]: \u001B[0m eta: 0:07:03  iter: 759  total_loss: 0.3533  loss_cls: 0.09457  loss_box_reg: 0.06451  loss_rpn_cls: 0.09292  loss_rpn_loc: 0.06473    time: 0.2434  last_time: 0.2272  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00018981  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:27:25 d2.utils.events]: \u001B[0m eta: 0:06:58  iter: 779  total_loss: 0.4229  loss_cls: 0.1152  loss_box_reg: 0.09652  loss_rpn_cls: 0.05062  loss_rpn_loc: 0.1387    time: 0.2436  last_time: 0.2468  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00019481  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:27:30 d2.utils.events]: \u001B[0m eta: 0:06:53  iter: 799  total_loss: 0.5408  loss_cls: 0.1387  loss_box_reg: 0.1012  loss_rpn_cls: 0.07548  loss_rpn_loc: 0.1957    time: 0.2437  last_time: 0.2481  data_time: 0.0011  last_data_time: 0.0013   lr: 0.0001998  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:27:35 d2.utils.events]: \u001B[0m eta: 0:06:48  iter: 819  total_loss: 0.4057  loss_cls: 0.1306  loss_box_reg: 0.112  loss_rpn_cls: 0.06042  loss_rpn_loc: 0.07705    time: 0.2437  last_time: 0.2623  data_time: 0.0011  last_data_time: 0.0011   lr: 0.0002048  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:27:40 d2.utils.events]: \u001B[0m eta: 0:06:44  iter: 839  total_loss: 0.5307  loss_cls: 0.0919  loss_box_reg: 0.05912  loss_rpn_cls: 0.0735  loss_rpn_loc: 0.2366    time: 0.2444  last_time: 0.3232  data_time: 0.0017  last_data_time: 0.0050   lr: 0.00020979  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:27:47 d2.utils.events]: \u001B[0m eta: 0:06:40  iter: 859  total_loss: 0.4044  loss_cls: 0.1138  loss_box_reg: 0.08428  loss_rpn_cls: 0.06216  loss_rpn_loc: 0.09527    time: 0.2470  last_time: 0.3145  data_time: 0.0031  last_data_time: 0.0015   lr: 0.00021479  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:27:54 d2.utils.events]: \u001B[0m eta: 0:06:36  iter: 879  total_loss: 0.365  loss_cls: 0.1174  loss_box_reg: 0.08067  loss_rpn_cls: 0.05964  loss_rpn_loc: 0.08901    time: 0.2485  last_time: 0.2276  data_time: 0.0030  last_data_time: 0.0019   lr: 0.00021978  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:27:59 d2.utils.events]: \u001B[0m eta: 0:06:32  iter: 899  total_loss: 0.5139  loss_cls: 0.116  loss_box_reg: 0.08494  loss_rpn_cls: 0.06384  loss_rpn_loc: 0.2502    time: 0.2487  last_time: 0.2930  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00022478  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:28:04 d2.utils.events]: \u001B[0m eta: 0:06:27  iter: 919  total_loss: 0.3741  loss_cls: 0.1145  loss_box_reg: 0.0736  loss_rpn_cls: 0.0599  loss_rpn_loc: 0.1228    time: 0.2487  last_time: 0.2445  data_time: 0.0011  last_data_time: 0.0010   lr: 0.00022977  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:28:09 d2.utils.events]: \u001B[0m eta: 0:06:22  iter: 939  total_loss: 0.4719  loss_cls: 0.1009  loss_box_reg: 0.07406  loss_rpn_cls: 0.06067  loss_rpn_loc: 0.1499    time: 0.2485  last_time: 0.1950  data_time: 0.0011  last_data_time: 0.0010   lr: 0.00023477  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:28:14 d2.utils.events]: \u001B[0m eta: 0:06:17  iter: 959  total_loss: 0.3588  loss_cls: 0.08874  loss_box_reg: 0.07606  loss_rpn_cls: 0.08085  loss_rpn_loc: 0.09002    time: 0.2485  last_time: 0.2551  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00023976  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:28:19 d2.utils.events]: \u001B[0m eta: 0:06:13  iter: 979  total_loss: 0.4377  loss_cls: 0.1189  loss_box_reg: 0.07404  loss_rpn_cls: 0.07283  loss_rpn_loc: 0.1807    time: 0.2486  last_time: 0.2251  data_time: 0.0010  last_data_time: 0.0011   lr: 0.00024476  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:28:23 d2.utils.events]: \u001B[0m eta: 0:06:08  iter: 999  total_loss: 0.3977  loss_cls: 0.1049  loss_box_reg: 0.08753  loss_rpn_cls: 0.0637  loss_rpn_loc: 0.1937    time: 0.2483  last_time: 0.1868  data_time: 0.0009  last_data_time: 0.0009   lr: 0.00024975  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:28:28 d2.utils.events]: \u001B[0m eta: 0:06:03  iter: 1019  total_loss: 0.4282  loss_cls: 0.1067  loss_box_reg: 0.08861  loss_rpn_cls: 0.06478  loss_rpn_loc: 0.1591    time: 0.2483  last_time: 0.2484  data_time: 0.0010  last_data_time: 0.0014   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:28:33 d2.utils.events]: \u001B[0m eta: 0:05:58  iter: 1039  total_loss: 0.5084  loss_cls: 0.138  loss_box_reg: 0.1059  loss_rpn_cls: 0.07347  loss_rpn_loc: 0.119    time: 0.2483  last_time: 0.2825  data_time: 0.0010  last_data_time: 0.0008   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:28:38 d2.utils.events]: \u001B[0m eta: 0:05:53  iter: 1059  total_loss: 0.3681  loss_cls: 0.1087  loss_box_reg: 0.06719  loss_rpn_cls: 0.05855  loss_rpn_loc: 0.1087    time: 0.2482  last_time: 0.2535  data_time: 0.0009  last_data_time: 0.0008   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:28:43 d2.utils.events]: \u001B[0m eta: 0:05:48  iter: 1079  total_loss: 0.3758  loss_cls: 0.1132  loss_box_reg: 0.07588  loss_rpn_cls: 0.04406  loss_rpn_loc: 0.09704    time: 0.2480  last_time: 0.2581  data_time: 0.0010  last_data_time: 0.0007   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:28:48 d2.utils.events]: \u001B[0m eta: 0:05:43  iter: 1099  total_loss: 0.4527  loss_cls: 0.1383  loss_box_reg: 0.1319  loss_rpn_cls: 0.04075  loss_rpn_loc: 0.1057    time: 0.2479  last_time: 0.2426  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:28:53 d2.utils.events]: \u001B[0m eta: 0:05:39  iter: 1119  total_loss: 0.6319  loss_cls: 0.1217  loss_box_reg: 0.09333  loss_rpn_cls: 0.06833  loss_rpn_loc: 0.2795    time: 0.2479  last_time: 0.2132  data_time: 0.0010  last_data_time: 0.0012   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:28:57 d2.utils.events]: \u001B[0m eta: 0:05:34  iter: 1139  total_loss: 0.4599  loss_cls: 0.1209  loss_box_reg: 0.09523  loss_rpn_cls: 0.07195  loss_rpn_loc: 0.168    time: 0.2477  last_time: 0.2280  data_time: 0.0010  last_data_time: 0.0013   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:29:02 d2.utils.events]: \u001B[0m eta: 0:05:29  iter: 1159  total_loss: 0.415  loss_cls: 0.126  loss_box_reg: 0.08497  loss_rpn_cls: 0.06464  loss_rpn_loc: 0.1047    time: 0.2476  last_time: 0.2441  data_time: 0.0010  last_data_time: 0.0008   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:29:07 d2.utils.events]: \u001B[0m eta: 0:05:24  iter: 1179  total_loss: 0.3163  loss_cls: 0.09989  loss_box_reg: 0.08268  loss_rpn_cls: 0.04663  loss_rpn_loc: 0.06544    time: 0.2475  last_time: 0.2542  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:29:12 d2.utils.events]: \u001B[0m eta: 0:05:19  iter: 1199  total_loss: 0.3094  loss_cls: 0.09263  loss_box_reg: 0.07202  loss_rpn_cls: 0.06414  loss_rpn_loc: 0.08748    time: 0.2474  last_time: 0.2916  data_time: 0.0010  last_data_time: 0.0011   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:29:17 d2.utils.events]: \u001B[0m eta: 0:05:14  iter: 1219  total_loss: 0.4686  loss_cls: 0.08192  loss_box_reg: 0.05141  loss_rpn_cls: 0.06329  loss_rpn_loc: 0.1571    time: 0.2475  last_time: 0.2626  data_time: 0.0009  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:29:22 d2.utils.events]: \u001B[0m eta: 0:05:10  iter: 1239  total_loss: 0.3923  loss_cls: 0.07757  loss_box_reg: 0.04658  loss_rpn_cls: 0.05817  loss_rpn_loc: 0.1328    time: 0.2475  last_time: 0.2642  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:29:27 d2.utils.events]: \u001B[0m eta: 0:05:05  iter: 1259  total_loss: 0.3547  loss_cls: 0.1162  loss_box_reg: 0.1022  loss_rpn_cls: 0.05138  loss_rpn_loc: 0.09119    time: 0.2475  last_time: 0.2916  data_time: 0.0010  last_data_time: 0.0007   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:29:32 d2.utils.events]: \u001B[0m eta: 0:05:00  iter: 1279  total_loss: 0.3762  loss_cls: 0.1165  loss_box_reg: 0.09816  loss_rpn_cls: 0.06437  loss_rpn_loc: 0.1167    time: 0.2476  last_time: 0.2590  data_time: 0.0011  last_data_time: 0.0018   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:29:37 d2.utils.events]: \u001B[0m eta: 0:04:55  iter: 1299  total_loss: 0.4177  loss_cls: 0.09152  loss_box_reg: 0.0734  loss_rpn_cls: 0.06122  loss_rpn_loc: 0.1821    time: 0.2476  last_time: 0.2232  data_time: 0.0011  last_data_time: 0.0012   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:29:42 d2.utils.events]: \u001B[0m eta: 0:04:50  iter: 1319  total_loss: 0.3486  loss_cls: 0.0905  loss_box_reg: 0.07823  loss_rpn_cls: 0.05504  loss_rpn_loc: 0.04244    time: 0.2477  last_time: 0.2800  data_time: 0.0010  last_data_time: 0.0006   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:29:47 d2.utils.events]: \u001B[0m eta: 0:04:46  iter: 1339  total_loss: 0.4235  loss_cls: 0.1108  loss_box_reg: 0.09548  loss_rpn_cls: 0.06712  loss_rpn_loc: 0.1589    time: 0.2477  last_time: 0.2678  data_time: 0.0009  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:29:52 d2.utils.events]: \u001B[0m eta: 0:04:41  iter: 1359  total_loss: 0.4354  loss_cls: 0.09731  loss_box_reg: 0.08219  loss_rpn_cls: 0.0595  loss_rpn_loc: 0.1641    time: 0.2476  last_time: 0.2542  data_time: 0.0010  last_data_time: 0.0008   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:29:57 d2.utils.events]: \u001B[0m eta: 0:04:36  iter: 1379  total_loss: 0.3352  loss_cls: 0.1072  loss_box_reg: 0.08588  loss_rpn_cls: 0.05075  loss_rpn_loc: 0.09869    time: 0.2477  last_time: 0.2549  data_time: 0.0011  last_data_time: 0.0011   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:30:02 d2.utils.events]: \u001B[0m eta: 0:04:31  iter: 1399  total_loss: 0.3623  loss_cls: 0.1059  loss_box_reg: 0.0674  loss_rpn_cls: 0.05795  loss_rpn_loc: 0.06656    time: 0.2476  last_time: 0.2247  data_time: 0.0011  last_data_time: 0.0012   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:30:06 d2.utils.events]: \u001B[0m eta: 0:04:26  iter: 1419  total_loss: 0.3962  loss_cls: 0.1272  loss_box_reg: 0.1047  loss_rpn_cls: 0.05133  loss_rpn_loc: 0.06088    time: 0.2473  last_time: 0.2399  data_time: 0.0010  last_data_time: 0.0011   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:30:12 d2.utils.events]: \u001B[0m eta: 0:04:21  iter: 1439  total_loss: 0.5535  loss_cls: 0.1277  loss_box_reg: 0.1116  loss_rpn_cls: 0.05188  loss_rpn_loc: 0.2206    time: 0.2474  last_time: 0.2561  data_time: 0.0010  last_data_time: 0.0012   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:30:16 d2.utils.events]: \u001B[0m eta: 0:04:16  iter: 1459  total_loss: 0.3828  loss_cls: 0.1357  loss_box_reg: 0.1014  loss_rpn_cls: 0.0444  loss_rpn_loc: 0.1109    time: 0.2474  last_time: 0.2228  data_time: 0.0010  last_data_time: 0.0007   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:30:22 d2.utils.events]: \u001B[0m eta: 0:04:12  iter: 1479  total_loss: 0.3217  loss_cls: 0.1192  loss_box_reg: 0.08917  loss_rpn_cls: 0.04922  loss_rpn_loc: 0.0923    time: 0.2475  last_time: 0.2404  data_time: 0.0010  last_data_time: 0.0008   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:30:26 d2.utils.events]: \u001B[0m eta: 0:04:07  iter: 1499  total_loss: 0.3707  loss_cls: 0.09669  loss_box_reg: 0.07118  loss_rpn_cls: 0.06291  loss_rpn_loc: 0.09813    time: 0.2475  last_time: 0.2322  data_time: 0.0009  last_data_time: 0.0007   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:30:31 d2.utils.events]: \u001B[0m eta: 0:04:02  iter: 1519  total_loss: 0.367  loss_cls: 0.1184  loss_box_reg: 0.1172  loss_rpn_cls: 0.04782  loss_rpn_loc: 0.07915    time: 0.2475  last_time: 0.2482  data_time: 0.0009  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:30:36 d2.utils.events]: \u001B[0m eta: 0:03:57  iter: 1539  total_loss: 0.4808  loss_cls: 0.1374  loss_box_reg: 0.09374  loss_rpn_cls: 0.039  loss_rpn_loc: 0.1301    time: 0.2475  last_time: 0.2500  data_time: 0.0010  last_data_time: 0.0010   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:30:41 d2.utils.events]: \u001B[0m eta: 0:03:52  iter: 1559  total_loss: 0.3578  loss_cls: 0.1281  loss_box_reg: 0.1249  loss_rpn_cls: 0.04502  loss_rpn_loc: 0.07688    time: 0.2475  last_time: 0.2058  data_time: 0.0010  last_data_time: 0.0011   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:30:46 d2.utils.events]: \u001B[0m eta: 0:03:48  iter: 1579  total_loss: 0.4008  loss_cls: 0.1098  loss_box_reg: 0.1014  loss_rpn_cls: 0.05181  loss_rpn_loc: 0.1182    time: 0.2475  last_time: 0.2852  data_time: 0.0009  last_data_time: 0.0010   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:30:51 d2.utils.events]: \u001B[0m eta: 0:03:43  iter: 1599  total_loss: 0.3691  loss_cls: 0.1259  loss_box_reg: 0.09096  loss_rpn_cls: 0.04331  loss_rpn_loc: 0.109    time: 0.2474  last_time: 0.2807  data_time: 0.0010  last_data_time: 0.0010   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:30:56 d2.utils.events]: \u001B[0m eta: 0:03:38  iter: 1619  total_loss: 0.4099  loss_cls: 0.1274  loss_box_reg: 0.09555  loss_rpn_cls: 0.04715  loss_rpn_loc: 0.08832    time: 0.2475  last_time: 0.2461  data_time: 0.0010  last_data_time: 0.0010   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:31:01 d2.utils.events]: \u001B[0m eta: 0:03:33  iter: 1639  total_loss: 0.4233  loss_cls: 0.1267  loss_box_reg: 0.1053  loss_rpn_cls: 0.04833  loss_rpn_loc: 0.1019    time: 0.2475  last_time: 0.2455  data_time: 0.0010  last_data_time: 0.0010   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:31:06 d2.utils.events]: \u001B[0m eta: 0:03:29  iter: 1659  total_loss: 0.3463  loss_cls: 0.09751  loss_box_reg: 0.07572  loss_rpn_cls: 0.0688  loss_rpn_loc: 0.07282    time: 0.2476  last_time: 0.2880  data_time: 0.0010  last_data_time: 0.0008   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:31:11 d2.utils.events]: \u001B[0m eta: 0:03:23  iter: 1679  total_loss: 0.3983  loss_cls: 0.1029  loss_box_reg: 0.07759  loss_rpn_cls: 0.05787  loss_rpn_loc: 0.2248    time: 0.2475  last_time: 0.2164  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:31:16 d2.utils.events]: \u001B[0m eta: 0:03:18  iter: 1699  total_loss: 0.6067  loss_cls: 0.1111  loss_box_reg: 0.07989  loss_rpn_cls: 0.07227  loss_rpn_loc: 0.2215    time: 0.2475  last_time: 0.2729  data_time: 0.0010  last_data_time: 0.0010   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:31:21 d2.utils.events]: \u001B[0m eta: 0:03:14  iter: 1719  total_loss: 0.4059  loss_cls: 0.1119  loss_box_reg: 0.09648  loss_rpn_cls: 0.05686  loss_rpn_loc: 0.1578    time: 0.2476  last_time: 0.2421  data_time: 0.0010  last_data_time: 0.0007   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:31:26 d2.utils.events]: \u001B[0m eta: 0:03:09  iter: 1739  total_loss: 0.3978  loss_cls: 0.1039  loss_box_reg: 0.07691  loss_rpn_cls: 0.04315  loss_rpn_loc: 0.1129    time: 0.2476  last_time: 0.2094  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:31:31 d2.utils.events]: \u001B[0m eta: 0:03:04  iter: 1759  total_loss: 0.3339  loss_cls: 0.09679  loss_box_reg: 0.08765  loss_rpn_cls: 0.08324  loss_rpn_loc: 0.1035    time: 0.2476  last_time: 0.2462  data_time: 0.0010  last_data_time: 0.0007   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:31:36 d2.utils.events]: \u001B[0m eta: 0:02:59  iter: 1779  total_loss: 0.4026  loss_cls: 0.1002  loss_box_reg: 0.07969  loss_rpn_cls: 0.04714  loss_rpn_loc: 0.1228    time: 0.2476  last_time: 0.2878  data_time: 0.0011  last_data_time: 0.0012   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:31:41 d2.utils.events]: \u001B[0m eta: 0:02:54  iter: 1799  total_loss: 0.348  loss_cls: 0.1086  loss_box_reg: 0.09957  loss_rpn_cls: 0.05048  loss_rpn_loc: 0.09739    time: 0.2477  last_time: 0.2437  data_time: 0.0010  last_data_time: 0.0006   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:31:46 d2.utils.events]: \u001B[0m eta: 0:02:50  iter: 1819  total_loss: 0.4013  loss_cls: 0.1246  loss_box_reg: 0.09706  loss_rpn_cls: 0.04734  loss_rpn_loc: 0.1152    time: 0.2478  last_time: 0.2845  data_time: 0.0011  last_data_time: 0.0015   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:31:51 d2.utils.events]: \u001B[0m eta: 0:02:44  iter: 1839  total_loss: 0.3731  loss_cls: 0.1095  loss_box_reg: 0.09552  loss_rpn_cls: 0.05538  loss_rpn_loc: 0.07958    time: 0.2478  last_time: 0.2423  data_time: 0.0011  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:31:56 d2.utils.events]: \u001B[0m eta: 0:02:39  iter: 1859  total_loss: 0.3882  loss_cls: 0.09452  loss_box_reg: 0.07558  loss_rpn_cls: 0.05874  loss_rpn_loc: 0.1848    time: 0.2478  last_time: 0.2148  data_time: 0.0011  last_data_time: 0.0012   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:32:01 d2.utils.events]: \u001B[0m eta: 0:02:33  iter: 1879  total_loss: 0.3365  loss_cls: 0.1049  loss_box_reg: 0.09135  loss_rpn_cls: 0.05351  loss_rpn_loc: 0.06832    time: 0.2477  last_time: 0.2447  data_time: 0.0011  last_data_time: 0.0008   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:32:06 d2.utils.events]: \u001B[0m eta: 0:02:28  iter: 1899  total_loss: 0.3586  loss_cls: 0.12  loss_box_reg: 0.1037  loss_rpn_cls: 0.04568  loss_rpn_loc: 0.09281    time: 0.2478  last_time: 0.2504  data_time: 0.0011  last_data_time: 0.0008   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:32:11 d2.utils.events]: \u001B[0m eta: 0:02:23  iter: 1919  total_loss: 0.367  loss_cls: 0.1208  loss_box_reg: 0.09459  loss_rpn_cls: 0.04633  loss_rpn_loc: 0.1298    time: 0.2479  last_time: 0.2411  data_time: 0.0010  last_data_time: 0.0005   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:32:16 d2.utils.events]: \u001B[0m eta: 0:02:18  iter: 1939  total_loss: 0.3403  loss_cls: 0.122  loss_box_reg: 0.09721  loss_rpn_cls: 0.0413  loss_rpn_loc: 0.0793    time: 0.2477  last_time: 0.2824  data_time: 0.0010  last_data_time: 0.0007   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:32:21 d2.utils.events]: \u001B[0m eta: 0:02:13  iter: 1959  total_loss: 0.3179  loss_cls: 0.09317  loss_box_reg: 0.06699  loss_rpn_cls: 0.04257  loss_rpn_loc: 0.1068    time: 0.2477  last_time: 0.2838  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:32:26 d2.utils.events]: \u001B[0m eta: 0:02:08  iter: 1979  total_loss: 0.3593  loss_cls: 0.1104  loss_box_reg: 0.08456  loss_rpn_cls: 0.04707  loss_rpn_loc: 0.1225    time: 0.2477  last_time: 0.2746  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:32:31 d2.utils.events]: \u001B[0m eta: 0:02:04  iter: 1999  total_loss: 0.3485  loss_cls: 0.1075  loss_box_reg: 0.09378  loss_rpn_cls: 0.03392  loss_rpn_loc: 0.1149    time: 0.2477  last_time: 0.2335  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:32:36 d2.utils.events]: \u001B[0m eta: 0:01:59  iter: 2019  total_loss: 0.3076  loss_cls: 0.1063  loss_box_reg: 0.08007  loss_rpn_cls: 0.04859  loss_rpn_loc: 0.09319    time: 0.2476  last_time: 0.2477  data_time: 0.0010  last_data_time: 0.0007   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:32:41 d2.utils.events]: \u001B[0m eta: 0:01:54  iter: 2039  total_loss: 0.4771  loss_cls: 0.1128  loss_box_reg: 0.08762  loss_rpn_cls: 0.04921  loss_rpn_loc: 0.1454    time: 0.2477  last_time: 0.2510  data_time: 0.0009  last_data_time: 0.0011   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:32:46 d2.utils.events]: \u001B[0m eta: 0:01:49  iter: 2059  total_loss: 0.3439  loss_cls: 0.09848  loss_box_reg: 0.07746  loss_rpn_cls: 0.03065  loss_rpn_loc: 0.1274    time: 0.2478  last_time: 0.2790  data_time: 0.0010  last_data_time: 0.0012   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:32:51 d2.utils.events]: \u001B[0m eta: 0:01:44  iter: 2079  total_loss: 0.4838  loss_cls: 0.09285  loss_box_reg: 0.08196  loss_rpn_cls: 0.0404  loss_rpn_loc: 0.2114    time: 0.2478  last_time: 0.2811  data_time: 0.0010  last_data_time: 0.0011   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:32:56 d2.utils.events]: \u001B[0m eta: 0:01:39  iter: 2099  total_loss: 0.4648  loss_cls: 0.101  loss_box_reg: 0.08576  loss_rpn_cls: 0.05416  loss_rpn_loc: 0.1543    time: 0.2477  last_time: 0.2951  data_time: 0.0009  last_data_time: 0.0010   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:33:01 d2.utils.events]: \u001B[0m eta: 0:01:34  iter: 2119  total_loss: 0.3632  loss_cls: 0.08795  loss_box_reg: 0.07794  loss_rpn_cls: 0.03885  loss_rpn_loc: 0.1572    time: 0.2477  last_time: 0.2322  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:33:05 d2.utils.events]: \u001B[0m eta: 0:01:29  iter: 2139  total_loss: 0.3825  loss_cls: 0.1301  loss_box_reg: 0.1196  loss_rpn_cls: 0.03227  loss_rpn_loc: 0.08672    time: 0.2477  last_time: 0.2591  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:33:11 d2.utils.events]: \u001B[0m eta: 0:01:24  iter: 2159  total_loss: 0.3483  loss_cls: 0.1034  loss_box_reg: 0.09259  loss_rpn_cls: 0.04329  loss_rpn_loc: 0.08813    time: 0.2477  last_time: 0.2551  data_time: 0.0010  last_data_time: 0.0016   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:33:15 d2.utils.events]: \u001B[0m eta: 0:01:19  iter: 2179  total_loss: 0.3292  loss_cls: 0.09853  loss_box_reg: 0.08503  loss_rpn_cls: 0.04156  loss_rpn_loc: 0.09268    time: 0.2477  last_time: 0.2588  data_time: 0.0010  last_data_time: 0.0006   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:33:20 d2.utils.events]: \u001B[0m eta: 0:01:14  iter: 2199  total_loss: 0.3227  loss_cls: 0.1174  loss_box_reg: 0.1008  loss_rpn_cls: 0.04632  loss_rpn_loc: 0.0516    time: 0.2476  last_time: 0.2520  data_time: 0.0010  last_data_time: 0.0013   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:33:25 d2.utils.events]: \u001B[0m eta: 0:01:09  iter: 2219  total_loss: 0.5454  loss_cls: 0.1486  loss_box_reg: 0.1229  loss_rpn_cls: 0.05404  loss_rpn_loc: 0.1944    time: 0.2477  last_time: 0.2232  data_time: 0.0011  last_data_time: 0.0007   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:33:30 d2.utils.events]: \u001B[0m eta: 0:01:04  iter: 2239  total_loss: 0.3252  loss_cls: 0.1068  loss_box_reg: 0.07776  loss_rpn_cls: 0.04902  loss_rpn_loc: 0.07341    time: 0.2477  last_time: 0.2554  data_time: 0.0010  last_data_time: 0.0008   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:33:35 d2.utils.events]: \u001B[0m eta: 0:00:59  iter: 2259  total_loss: 0.4421  loss_cls: 0.1237  loss_box_reg: 0.1201  loss_rpn_cls: 0.03845  loss_rpn_loc: 0.1377    time: 0.2476  last_time: 0.2614  data_time: 0.0009  last_data_time: 0.0012   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:33:40 d2.utils.events]: \u001B[0m eta: 0:00:54  iter: 2279  total_loss: 0.3997  loss_cls: 0.1138  loss_box_reg: 0.08828  loss_rpn_cls: 0.04658  loss_rpn_loc: 0.1033    time: 0.2477  last_time: 0.2927  data_time: 0.0011  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:33:45 d2.utils.events]: \u001B[0m eta: 0:00:49  iter: 2299  total_loss: 0.3804  loss_cls: 0.1045  loss_box_reg: 0.08571  loss_rpn_cls: 0.03649  loss_rpn_loc: 0.1331    time: 0.2476  last_time: 0.2449  data_time: 0.0010  last_data_time: 0.0004   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:33:50 d2.utils.events]: \u001B[0m eta: 0:00:44  iter: 2319  total_loss: 0.3928  loss_cls: 0.1263  loss_box_reg: 0.1234  loss_rpn_cls: 0.0301  loss_rpn_loc: 0.1065    time: 0.2477  last_time: 0.2841  data_time: 0.0010  last_data_time: 0.0008   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:33:55 d2.utils.events]: \u001B[0m eta: 0:00:39  iter: 2339  total_loss: 0.3244  loss_cls: 0.1003  loss_box_reg: 0.07816  loss_rpn_cls: 0.04386  loss_rpn_loc: 0.1126    time: 0.2476  last_time: 0.2978  data_time: 0.0009  last_data_time: 0.0007   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:34:00 d2.utils.events]: \u001B[0m eta: 0:00:34  iter: 2359  total_loss: 0.3762  loss_cls: 0.117  loss_box_reg: 0.106  loss_rpn_cls: 0.04212  loss_rpn_loc: 0.07281    time: 0.2476  last_time: 0.2509  data_time: 0.0010  last_data_time: 0.0008   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:34:05 d2.utils.events]: \u001B[0m eta: 0:00:29  iter: 2379  total_loss: 0.5048  loss_cls: 0.1357  loss_box_reg: 0.1196  loss_rpn_cls: 0.04722  loss_rpn_loc: 0.1621    time: 0.2476  last_time: 0.2196  data_time: 0.0010  last_data_time: 0.0011   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:34:10 d2.utils.events]: \u001B[0m eta: 0:00:24  iter: 2399  total_loss: 0.3002  loss_cls: 0.09426  loss_box_reg: 0.06174  loss_rpn_cls: 0.05167  loss_rpn_loc: 0.07786    time: 0.2476  last_time: 0.2139  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:34:15 d2.utils.events]: \u001B[0m eta: 0:00:19  iter: 2419  total_loss: 0.3098  loss_cls: 0.09638  loss_box_reg: 0.05729  loss_rpn_cls: 0.0378  loss_rpn_loc: 0.1858    time: 0.2475  last_time: 0.2541  data_time: 0.0010  last_data_time: 0.0009   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:34:20 d2.utils.events]: \u001B[0m eta: 0:00:14  iter: 2439  total_loss: 0.4047  loss_cls: 0.1021  loss_box_reg: 0.08043  loss_rpn_cls: 0.0534  loss_rpn_loc: 0.1556    time: 0.2475  last_time: 0.2837  data_time: 0.0010  last_data_time: 0.0008   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:34:24 d2.utils.events]: \u001B[0m eta: 0:00:09  iter: 2459  total_loss: 0.294  loss_cls: 0.105  loss_box_reg: 0.08412  loss_rpn_cls: 0.03515  loss_rpn_loc: 0.06885    time: 0.2475  last_time: 0.2231  data_time: 0.0010  last_data_time: 0.0011   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:34:29 d2.utils.events]: \u001B[0m eta: 0:00:04  iter: 2479  total_loss: 0.3886  loss_cls: 0.09008  loss_box_reg: 0.07655  loss_rpn_cls: 0.04843  loss_rpn_loc: 0.1816    time: 0.2475  last_time: 0.2096  data_time: 0.0009  last_data_time: 0.0007   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:34:35 d2.utils.events]: \u001B[0m eta: 0:00:00  iter: 2499  total_loss: 0.3069  loss_cls: 0.106  loss_box_reg: 0.08101  loss_rpn_cls: 0.04048  loss_rpn_loc: 0.08977    time: 0.2474  last_time: 0.2392  data_time: 0.0010  last_data_time: 0.0006   lr: 0.00025  max_mem: 3438M\n",
      "\u001B[32m[11/21 09:34:35 d2.engine.hooks]: \u001B[0mOverall training speed: 2498 iterations in 0:10:18 (0.2474 s / it)\n",
      "\u001B[32m[11/21 09:34:35 d2.engine.hooks]: \u001B[0mTotal training time: 0:10:19 (0:00:01 on hooks)\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "def finetune_model(model_name, dataset_name, num_classes):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(model_name))\n",
    "    cfg.DATASETS.TRAIN = (dataset_name,)\n",
    "    cfg.DATASETS.TEST = ()\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2 \n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model_name) \n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2 # IMS = Images per batch\n",
    "    cfg.SOLVER.BASE_LR = 0.00025 # LR = Learning Rate\n",
    "    cfg.SOLVER.MAX_ITER = 2500 # No. of iterations\n",
    "    cfg.SOLVER.STEPS = []  # do not decay learning rate\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256 # No. of RoIs per image\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes  # 5 classes for our dataset\n",
    "    cfg.OUTPUT_DIR = \"output\"\n",
    "\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    trainer = DefaultTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "\n",
    "# Delete the output folder if it already exists\n",
    "!rmdir /s /q output\n",
    "\n",
    "# Fine-tuning the Faster R-CNN with a ResNet-50 backbone model on our dataset\n",
    "finetune_model(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\", \"my_dataset\", 5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T15:34:35.390499500Z",
     "start_time": "2023-11-21T15:24:08.016309500Z"
    }
   },
   "id": "153878c5d3030eae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Real-Time Model Competition Setup\n",
    "\n",
    "This section focuses on setting up a real-time competition between the models using a video of animals. We'll download the video and its annotations, process the video in real-time, and display the predictions. This will allow us to compare the models' performance in a dynamic environment.\n",
    "\n",
    "### Downloading the Video and Annotations\n",
    "\n",
    "First, let's download the video and its annotations:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8b70c13c810317b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file video_data already exists.\n"
     ]
    }
   ],
   "source": [
    "# Video and annotations URLs\n",
    "video_url = \"https://github.com/D-Gaspa/Animal-BoVW-Classifier/releases/download/1.0/animals_video.zip\"\n",
    "\n",
    "# Download the video and annotations\n",
    "response = requests.get(video_url)\n",
    "zip_file = ZipFile(BytesIO(response.content))\n",
    "# Create a folder to extract the video and annotations\n",
    "!mkdir video_data\n",
    "# Extract the video and annotations to the created folder\n",
    "zip_file.extractall(\"video_data\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T15:34:46.720887300Z",
     "start_time": "2023-11-21T15:34:35.394018300Z"
    }
   },
   "id": "7cb4193d57384afc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Real-Time Processing and Display\n",
    "\n",
    "Next, we'll process the video in real-time and display the predictions:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ed296649d9a0839"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[11/21 09:34:47 d2.checkpoint.detection_checkpoint]: \u001B[0m[DetectionCheckpointer] Loading from output/model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "# Function to load the finetuned model\n",
    "def load_finetuned_model(weights_path):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5  # Adjust based on your dataset\n",
    "    cfg.MODEL.WEIGHTS = weights_path\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.15  # Set threshold for this model\n",
    "    return DefaultPredictor(cfg), cfg\n",
    "\n",
    "# Load the finetuned model\n",
    "finetuned_model, finetuned_cfg = load_finetuned_model(\"output/model_final.pth\")\n",
    "\n",
    "video = cv2.VideoCapture(\"video_data/animals_video.mp4\")\n",
    "\n",
    "# Initialize lists to store results\n",
    "results_model_1 = []\n",
    "results_model_2 = []\n",
    "results_finetuned = []\n",
    "\n",
    "frame_count = 0  # To keep track of the frame number\n",
    "\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (1920, 1080))  # Resize frame\n",
    "    \n",
    "    outputs_1 = model_1(frame)\n",
    "    outputs_2 = model_2(frame)\n",
    "    finetuned_outputs = finetuned_model(frame)\n",
    "    \n",
    "    # Store the outputs along with the frame number\n",
    "    results_model_1.append((frame_count, outputs_1))\n",
    "    results_model_2.append((frame_count, outputs_2))\n",
    "    results_finetuned.append((frame_count, finetuned_outputs))\n",
    "\n",
    "    v1 = Visualizer(frame, MetadataCatalog.get(\"my_dataset\"), scale=0.25, instance_mode=ColorMode.IMAGE)\n",
    "    v2 = Visualizer(frame, MetadataCatalog.get(\"my_dataset\"), scale=0.25, instance_mode=ColorMode.IMAGE)\n",
    "    v3 = Visualizer(frame, MetadataCatalog.get(\"my_dataset\"), scale=0.25, instance_mode=ColorMode.IMAGE)\n",
    "\n",
    "    out1 = v1.draw_instance_predictions(outputs_1[\"instances\"].to(\"cpu\")).get_image()\n",
    "    out2 = v2.draw_instance_predictions(outputs_2[\"instances\"].to(\"cpu\")).get_image()\n",
    "    out3 = v3.draw_instance_predictions(finetuned_outputs[\"instances\"].to(\"cpu\")).get_image()\n",
    "\n",
    "    # Label the outputs\n",
    "    out1 = cv2.putText(out1, \"Model 1\", (5, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    out2 = cv2.putText(out2, \"Model 2\", (5, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    out3 = cv2.putText(out3, \"Finetuned Model\", (5, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    # Combine outputs for side-by-side comparison\n",
    "    combined_output = cv2.hconcat([out1, out2, out3])\n",
    "    cv2.imshow(\"Model Comparisons\", combined_output)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    frame_count += 1\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T15:41:26.187314300Z",
     "start_time": "2023-11-21T15:34:46.727223100Z"
    }
   },
   "id": "3802b1449891e01"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation and Reporting\n",
    "\n",
    "### Step 1: Load Ground Truth Annotations\n",
    "We'll load the ground truth annotations from the provided XML file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "946f02a42cd94e4b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "\n",
    "def parse_xml_annotations(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    annotations = {}\n",
    "    for track in root.findall('.//track'):\n",
    "        label = track.get('label')\n",
    "        for box in track.findall('./box'):\n",
    "            if box.get('outside') == '1':  # Skip boxes marked as outside\n",
    "                continue\n",
    "\n",
    "            frame = int(box.get('frame'))\n",
    "            bbox = [float(box.get(coord)) for coord in ['xtl', 'ytl', 'xbr', 'ybr']]\n",
    "\n",
    "            if frame not in annotations:\n",
    "                annotations[frame] = []\n",
    "            annotations[frame].append({'bbox': bbox, 'label': label})\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "annotations = parse_xml_annotations('video_data/annotations.xml')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T15:41:26.213653Z",
     "start_time": "2023-11-21T15:41:26.191314900Z"
    }
   },
   "id": "48bd673f16ca1de3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Compare Predictions with Ground Truth\n",
    "We'll create a function to compare the model predictions against the ground truth annotations. This function will calculate metrics such as Precision, Recall, and F1 Score."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9c78c167361d29f"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    # Unpack the coordinates\n",
    "    x1_min, y1_min, x1_max, y1_max = box1\n",
    "    x2_min, y2_min, x2_max, y2_max = box2\n",
    "\n",
    "    # Calculate the (x, y)-coordinates of the intersection rectangle\n",
    "    x_inter_min = max(x1_min, x2_min)\n",
    "    y_inter_min = max(y1_min, y2_min)\n",
    "    x_inter_max = min(x1_max, x2_max)\n",
    "    y_inter_max = min(y1_max, y2_max)\n",
    "\n",
    "    # Compute the area of intersection rectangle\n",
    "    inter_area = max(0, x_inter_max - x_inter_min + 1) * max(0, y_inter_max - y_inter_min + 1)\n",
    "\n",
    "    # Compute the area of both the prediction and ground-truth rectangles\n",
    "    box1_area = (x1_max - x1_min + 1) * (y1_max - y1_min + 1)\n",
    "    box2_area = (x2_max - x2_min + 1) * (y2_max - y2_min + 1)\n",
    "\n",
    "    # Compute the intersection over union by taking the intersection area and dividing it by the sum of prediction + ground-truth areas - the intersection area\n",
    "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def match_predictions_with_annotations(predictions, annotations, iou_threshold=0.5):\n",
    "    TP, FP, FN = 0, 0, 0\n",
    "    \n",
    "    for frame_number, prediction in predictions:\n",
    "        frame_annotations = annotations.get(frame_number, [])\n",
    "        matched = [False] * len(frame_annotations)\n",
    "\n",
    "        if prediction is not None:\n",
    "            pred_boxes = prediction['instances'].pred_boxes.tensor.cpu().numpy()\n",
    "            for pred_box in pred_boxes:\n",
    "                best_iou = 0\n",
    "                best_match = -1\n",
    "\n",
    "                for i, annotation in enumerate(frame_annotations):\n",
    "                    iou = calculate_iou(pred_box, annotation['bbox'])\n",
    "\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_match = i\n",
    "\n",
    "                if best_iou >= iou_threshold:\n",
    "                    matched[best_match] = True\n",
    "                else:\n",
    "                    FP += 1\n",
    "\n",
    "        FN += matched.count(False)\n",
    "        TP += sum(matched)\n",
    "\n",
    "    return TP, FP, FN\n",
    "\n",
    "def calculate_metrics(TP, FP, FN):\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Evaluation for Model 1\n",
    "TP_model_1, FP_model_1, FN_model_1 = match_predictions_with_annotations(results_model_1, annotations)\n",
    "precision_model_1, recall_model_1, f1_model_1 = calculate_metrics(TP_model_1, FP_model_1, FN_model_1)\n",
    "\n",
    "# Evaluation for Model 2\n",
    "TP_model_2, FP_model_2, FN_model_2 = match_predictions_with_annotations(results_model_2, annotations)\n",
    "precision_model_2, recall_model_2, f1_model_2 = calculate_metrics(TP_model_2, FP_model_2, FN_model_2)\n",
    "\n",
    "# Evaluation for Finetuned Model\n",
    "TP_finetuned, FP_finetuned, FN_finetuned = match_predictions_with_annotations(results_finetuned, annotations)\n",
    "precision_finetuned, recall_finetuned, f1_finetuned = calculate_metrics(TP_finetuned, FP_finetuned, FN_finetuned)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T15:41:26.324675700Z",
     "start_time": "2023-11-21T15:41:26.214662600Z"
    }
   },
   "id": "37a2c55f20067e01"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Visualize and Compare Results\n",
    "Visualize the results of the evaluation to compare the models' performances."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "788c9ab87cf9110d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x400 with 3 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you've calculated metrics for all models\n",
    "precisions = [precision_model_1, precision_model_2, precision_finetuned]\n",
    "recalls = [recall_model_1, recall_model_2, recall_finetuned]\n",
    "f1_scores = [f1_model_1, f1_model_2, f1_finetuned]\n",
    "\n",
    "# Create bar plots for each metric\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.bar(['Model 1', 'Model 2', 'Finetuned'], precisions)\n",
    "plt.title('Precision')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(['Model 1', 'Model 2', 'Finetuned'], recalls)\n",
    "plt.title('Recall')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.bar(['Model 1', 'Model 2', 'Finetuned'], f1_scores)\n",
    "plt.title('F1 Score')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T15:41:26.515172600Z",
     "start_time": "2023-11-21T15:41:26.326676500Z"
    }
   },
   "id": "1d6db14002caf9c4"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: Precision = 0.5888013998250219, Recall = 0.9360222531293463, F1 Score = 0.7228786251342643\n",
      "Model 2: Precision = 0.5717884130982368, Recall = 0.9471488178025035, F1 Score = 0.7130890052356021\n",
      "Finetuned Model: Precision = 0.2828207051762941, Recall = 0.5243393602225312, F1 Score = 0.36744639376218324\n",
      "Winner: Model 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model 1: Precision = {precision_model_1}, Recall = {recall_model_1}, F1 Score = {f1_model_1}\")\n",
    "print(f\"Model 2: Precision = {precision_model_2}, Recall = {recall_model_2}, F1 Score = {f1_model_2}\")\n",
    "print(f\"Finetuned Model: Precision = {precision_finetuned}, Recall = {recall_finetuned}, F1 Score = {f1_finetuned}\")\n",
    "\n",
    "# get the highest F1 score to determine the winner\n",
    "highest_f1_score = max(f1_model_1, f1_model_2, f1_finetuned)\n",
    "\n",
    "print(f\"Winner: {'Model 1' if highest_f1_score == f1_model_1 else 'Model 2' if highest_f1_score == f1_model_2 else 'Finetuned Model'}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T15:41:26.604499900Z",
     "start_time": "2023-11-21T15:41:26.513188500Z"
    }
   },
   "id": "a081d5674e41fe3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "This section will give us insights into the performance of each model in detecting animals in real-time, guiding future improvements.\n",
    "\n",
    "it seems that Model 1 and Model 2 have higher recall rates, suggesting they are better at detecting relevant objects. The Finetuned Model, on the other hand, has the highest precision (5000 max iter, 0.2 threshold) but significantly lower recall, indicating it is more conservative in making predictions, leading to fewer false positives but missing more true objects. This is a typical trade-off in object detection models: a model may be tuned to be either more sensitive (high recall, lower precision) or more specific (high precision, lower recall). \n",
    "Increasing the number of iterations did not improve the Finetuned Model's performance, so we can conclude that the model is not underfitting. We also notice that the Finetuned Model fails to detect animals in small areas, such as the fox in the bottom left corner of the video. This is likely due to the model being trained on a dataset with larger animals, so it struggles to detect smaller animals.\n",
    "\n",
    "The F1 score, which balances precision and recall, suggests that Model 1 and Model 2 perform similarly and better than the Finetuned Model in this scenario."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f06fd59036e2fbf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Winner\n",
    "\n",
    "It was a close competition, but **Model 1** is the winner! It has the highest F1 score, which is the best metric for our scenario. \n",
    "\n",
    "Congratulations on completing this project! We hope you enjoyed it and learned something new. Feel free to explore the project further by trying out different models, datasets, and evaluation metrics. You can also check out the [Detectron2 documentation](https://detectron2.readthedocs.io/en/latest/index.html) to learn more about the library and its capabilities."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18ce36d60faedfcb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
